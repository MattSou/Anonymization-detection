Ici on trouve les expérimentations préliminaires, annexes, ou non abouties les plus intéressantes. Voici également une liste de pistes que j'ai trouvées intéressantes pour la suite :

- [LISA](https://github.com/dvlab-research/LISA ) : LLM multi-modal
- [DETR](https://github.com/facebookresearch/detr.git) : End-to-End object detection
- [Swin-Transformer](https://github.com/microsoft/Swin-Transformer.git) : Hierarchical Vision Transformers
- [EVP](https://github.com/NiFangBaAGe/Explicit-Visual-Prompt.git) : Explicit Visual Prompting for Low-Level Structure Segmentations (utilisé pour les masques defocus)
- [SRM et Two Stream FasterRCNN](https://arxiv.org/pdf/1805.04953) : Learning Rich Features for Image Manipulation Detection
