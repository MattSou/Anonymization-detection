{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer pour pré-traiter les images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Charger et pré-traiter les images\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "# Utiliser un modèle pré-entraîné pour extraire les caractéristiques\n",
    "def extract_features(model, img_path, device):\n",
    "    img = load_and_preprocess_image(img_path).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = model(img)\n",
    "    return features.cpu().numpy().flatten()\n",
    "\n",
    "def charge_feature(model, device, image_paths):\n",
    "    # Dossier contenant les images\n",
    "    \n",
    "    # Extraire les caractéristiques pour toutes les images\n",
    "    features = np.array([extract_features(model, img_path, device) for img_path in image_paths])\n",
    "\n",
    "    # Normaliser les vecteurs de caractéristiques\n",
    "    features_normalized = normalize(features, norm='l2')\n",
    "\n",
    "    return features_normalized\n",
    "\n",
    "def cluster_features(similarity_matrix, eps = 0.07, min_samples = 2):\n",
    "    dbscan = DBSCAN(metric='precomputed', eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(1 - similarity_matrix)\n",
    "    return labels\n",
    "\n",
    "def find_indices(similarity_matrix, threshold=1):\n",
    "    truth = similarity_matrix>threshold\n",
    "    indices = []\n",
    "    for i in range(len(truth)):\n",
    "        for j in range(len(truth)):\n",
    "            if truth[i][j]:\n",
    "                indices.append((i, j))\n",
    "    return indices\n",
    "\n",
    "def compute_average_distance(features):\n",
    "    distances = []\n",
    "    for i, feature in enumerate(features):\n",
    "        distances.append(np.mean(np.linalg.norm(features - feature, axis=1)))\n",
    "    return distances\n",
    "\n",
    "def compute_centers(features, labels, image_paths):\n",
    "    representative_images = {}\n",
    "    for cluster_label in np.unique(labels):\n",
    "        cluster_features = features[labels == cluster_label]\n",
    "        cluster_distances = compute_average_distance(cluster_features)\n",
    "        representative_image_index = np.argmin(cluster_distances)\n",
    "        representative_images[cluster_label]=image_paths[np.where(labels == cluster_label)[0][representative_image_index]]\n",
    "    return representative_images\n",
    "\n",
    "def convert_dict(dic):\n",
    "    converted_dict = {str(key): value for key, value in dic.items()}\n",
    "    return converted_dict\n",
    "\n",
    "def cluster_video(dataset, model, device, video, return_similarities=False):\n",
    "    channel = video[:3]\n",
    "    if channel in ['c+n', 'bft']:\n",
    "        eps = 0.05\n",
    "    else:\n",
    "        eps = 0.1\n",
    "    image_dir = os.path.join(dataset, video)\n",
    "    image_paths = np.sort([os.path.join(image_dir, fname) for fname in os.listdir(image_dir) if fname.endswith(('jpg', 'jpeg', 'png'))])\n",
    "    features = charge_feature(model, device, image_paths)\n",
    "    similarity_matrix = cosine_similarity(features)\n",
    "    indices_to_check = find_indices(similarity_matrix, 1)\n",
    "    for i, j in indices_to_check:\n",
    "        similarity_matrix[i][j] = 1\n",
    "        similarity_matrix[j][i] = 1\n",
    "    labels = cluster_features(similarity_matrix, eps=eps)\n",
    "    representative_images = compute_centers(features, labels, image_paths)\n",
    "    enum_clust = np.unique(labels)\n",
    "    dic_clust = {i:[] for i in enum_clust}\n",
    "\n",
    "    mean_similarity = (np.sum(similarity_matrix)-len(similarity_matrix))/(len(similarity_matrix)**2-len(similarity_matrix))\n",
    "    for i, label in enumerate(labels):\n",
    "        dic_clust[label].append(image_paths[i])\n",
    "    if -1 in dic_clust:\n",
    "        final_imgs = dic_clust[-1].copy()\n",
    "    else:\n",
    "        final_imgs = []\n",
    "    for i in representative_images:\n",
    "        if i!=-1:\n",
    "            final_imgs.append(representative_images[i])\n",
    "    \n",
    "    count_track = {\n",
    "        \"original_nb_img\": len(image_paths),\n",
    "        \"reduced_nb_img\": len(final_imgs),\n",
    "        \"nb_clusters\": len(np.unique(labels))-1,\n",
    "        \"nb_outliers\": len(dic_clust[-1]) if -1 in dic_clust else 0,\n",
    "        \"mean_similarity\": mean_similarity\n",
    "        }\n",
    "    if return_similarities:\n",
    "        return final_imgs, convert_dict(dic_clust), count_track, similarity_matrix\n",
    "    else:\n",
    "        return final_imgs, convert_dict(dic_clust), count_track\n",
    "\n",
    "\n",
    "def main(dataset, video_list=None):\n",
    "    img_list = {}\n",
    "    clusters = {}\n",
    "    metadata = {}\n",
    "    error_videos = []\n",
    "    if video_list is None:\n",
    "        video_list = os.listdir(dataset)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model = torch.nn.Sequential(*list(model.children())[:-1])  # Supprimer la dernière couche FC\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    sims = []\n",
    "    for i,video in enumerate(video_list):\n",
    "        \n",
    "        #print(video)\n",
    "        try:\n",
    "            final_imgs, dic_clust, count_track, sim = cluster_video(dataset, model, device, video, return_similarities=True)\n",
    "\n",
    "        except:\n",
    "            print(f\"Error with video {video}\")\n",
    "            error_videos.append(video)\n",
    "            continue\n",
    "        img_list[video] = final_imgs\n",
    "        clusters[video] = dic_clust        \n",
    "        metadata[video] = count_track\n",
    "        sims.append([video, sim])\n",
    "\n",
    "        print(f\"Video {video} ok : {count_track}\")\n",
    "        print(f\"Progression : {i+1}/{len(video_list)}\")\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "\n",
    "    with open('img_list2.json', 'w') as f:\n",
    "        json.dump(img_list, f)\n",
    "    \n",
    "    with open('clusters2.json', 'w') as f:\n",
    "        json.dump(clusters, f)\n",
    "    \n",
    "    return img_list, clusters, metadata, sims, error_videos\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = \"bft_20230620T184222\"\n",
    "final_imgs, dic_clust, count_track = cluster_video(\"/home/msouda/Datasets/true_anonymized\", model, device, video)\n",
    "print(f\"Video {video} ok : {count_track}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, clusters, metadata, sims, error_videos = main('/home/msouda/Datasets/true_anonymized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel, sim in sims:\n",
    "    np.save(f\"cluster_similarities/{channel}_sim.npy\", sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel, sim in sims:\n",
    "    tmp = [sim[i][j] for i in range(len(sim)) for j in range(i+1, len(sim))]\n",
    "    plt.hist(tmp, bins=100)\n",
    "    plt.title(channel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata_clusters.json', 'w') as f:\n",
    "        json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(metadata, orient='index').sort_values(by='nb_outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_videos = pd.read_csv('metadata_videos.csv').sort_values(by='duration').query('duration<150').assign(video_id=lambda x: x['video_id'].apply(lambda x: x.split('/')[-1]))\n",
    "metadata_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, clusters, metadata = main('/home/msouda/Datasets/true_anonymized', video_list=metadata_videos['video_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame.from_dict(metadata, orient='index').sort_values(by='nb_outliers')\n",
    "#plt.plot(a[\"mean_similarity\"], a[\"nb_outliers\"], 'o', label='Outliers')\n",
    "plt.plot(a[\"mean_similarity\"], a[\"nb_clusters\"], 'o', label='Clusters')\n",
    "#plt.plot(a[\"mean_similarity\"], a[\"original_nb_img\"], 'o', label='Original nb images')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.sort_values(by='mean_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for x in a.index:\n",
    "    _, _, _, sim = cluster_video('/home/msouda/Datasets/true_anonymized', model, device, x, return_similarities=True)\n",
    "    sim = [sim[i][j] for j in range(len(sim)) for i in range(j+1, len(sim))]\n",
    "    sims.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(a.index):\n",
    "    print(a['mean_similarity'][x], a['nb_outliers'][x], a['nb_clusters'][x], a['original_nb_img'][x])\n",
    "    plt.hist(a['sims'][x], bins=100, alpha=0.5, label=x)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = np.array([metadata[video][\"mean_similarity\"] for video in metadata])\n",
    "n_cl = np.array([metadata[video][\"nb_clusters\"] for video in metadata])\n",
    "n_out = np.array([metadata[video][\"nb_outliers\"] for video in metadata])\n",
    "plt.plot((ms-np.min(ms))/(np.max(ms)-np.min(ms)), label=\"mean_similarity\")\n",
    "plt.plot((n_cl-np.min(n_cl))/(np.max(n_cl)-np.min(n_cl)), label=\"nb_clusters\")\n",
    "plt.plot((n_out-np.min(n_out))/(np.max(n_out)-np.min(n_out)), label=\"nb_outliers\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ms, n_cl, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser un modèle pré-entraîné (ResNet-50 utilisé ici)\n",
    "\n",
    "\n",
    "print(device)\n",
    "print(image_paths)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser PCA pour réduire la dimensionnalité (optionnel mais recommandé pour de grands ensembles de données)\n",
    "pca = PCA(n_components=50)\n",
    "features_reduced = pca.fit_transform(features_normalized)\n",
    "features_reduced = normalize(features_reduced, norm='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(features_normalized>1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la matrice de similarité cosinus\n",
    "similarity_matrix = cosine_similarity(features_normalized)\n",
    "\n",
    "def find_indices(similarity_matrix, threshold=1):\n",
    "    truth = similarity_matrix>threshold\n",
    "    indices = []\n",
    "    for i in range(len(truth)):\n",
    "        for j in range(len(truth)):\n",
    "            if truth[i][j]:\n",
    "                indices.append((i, j))\n",
    "    return indices\n",
    "\n",
    "x =find_indices(similarity_matrix)\n",
    "for i, j in x:\n",
    "    #print(f\"Value on index {i} and {j} is {similarity_matrix[i][j]}\")\n",
    "    similarity_matrix[i][j] = 1\n",
    "\n",
    "# Appliquer DBSCAN avec la similarité cosinus comme mesure de distance\n",
    "dbscan = DBSCAN(metric='precomputed', eps=0.07, min_samples=2)\n",
    "labels = dbscan.fit_predict(1 - similarity_matrix)  # 1 - similarité pour la distance\n",
    "\n",
    "# Afficher les résultats\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Image {image_paths[i]} is in cluster {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic_clust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_distance(features):\n",
    "    distances = []\n",
    "    for i, feature in enumerate(features):\n",
    "        distances.append(np.mean(np.linalg.norm(features - feature, axis=1)))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_images = {}\n",
    "for cluster_label in np.unique(labels):\n",
    "    cluster_features = features[labels == cluster_label]\n",
    "    cluster_distances = compute_average_distance(cluster_features)\n",
    "    representative_image_index = np.argmin(cluster_distances)\n",
    "    representative_images[cluster_label]=image_paths[np.where(labels == cluster_label)[0][representative_image_index]]\n",
    "representative_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, len(enum_clust))\n",
    "list_img = dic_clust[enum_clust[i]]\n",
    "for path in list_img:\n",
    "    if path == representative_images[enum_clust[i]]:\n",
    "        print(f\"Representative image for cluster {enum_clust[i]}\")\n",
    "    img = Image.open(path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(final_imgs))\n",
    "print(len(representative_images)-1)\n",
    "print(len(dic_clust[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_imgs.append(representative_images[0])\n",
    "final_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in representative_images:\n",
    "    if i!=-1:\n",
    "        print(representative_images[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
