{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torchvision.models.resnet18(pretrained=True)\n",
    "model1.layer4 = torch.nn.Identity()\n",
    "model1.layer3 = torch.nn.Identity()\n",
    "model1.fc = torch.nn.Linear(128, 2)\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model parameters: {sum(p.numel() for p in model1.parameters())}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 540, 960)\n",
    "#z = torchvision.transforms.CenterCrop(960)(x)\n",
    "z = model1(x)\n",
    "z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamExtractor():\n",
    "    \"\"\"\n",
    "        Extracts cam features from the model\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "\n",
    "    def forward_pass_on_convolutions(self, x):\n",
    "        \"\"\"\n",
    "            Does a forward pass on convolutions, hooks the function at given layer\n",
    "        \"\"\"\n",
    "        conv_output = None\n",
    "        for module_pos, module in self.model.features._modules.items():\n",
    "            x = module(x)  # Forward\n",
    "            if int(module_pos) == self.target_layer:\n",
    "                conv_output = x  # Save the convolution output on that layer\n",
    "        return conv_output, x\n",
    "\n",
    "    def forward_pass(self, x):\n",
    "        \"\"\"\n",
    "            Does a full forward pass on the model\n",
    "        \"\"\"\n",
    "        # Forward pass on the convolutions\n",
    "        conv_output, x = self.forward_pass_on_convolutions(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        # Forward pass on the classifier\n",
    "        x = self.model.classifier(x)\n",
    "        return conv_output, x\n",
    "\n",
    "\n",
    "class ScoreCam():\n",
    "    \"\"\"\n",
    "        Produces class activation map\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        # Define extractor\n",
    "        self.extractor = CamExtractor(self.model, target_layer)\n",
    "\n",
    "    def generate_cam(self, input_image, target_class=None):\n",
    "        # Full forward pass\n",
    "        # conv_output is the output of convolutions at specified layer\n",
    "        # model_output is the final output of the model (1, 1000)\n",
    "        conv_output, model_output = self.extractor.forward_pass(input_image)\n",
    "        if target_class is None:\n",
    "            target_class = np.argmax(model_output.data.numpy())\n",
    "        # Get convolution outputs\n",
    "        target = conv_output[0]\n",
    "        # print(target)\n",
    "        # print(target.shape)\n",
    "        # Create empty numpy array for cam\n",
    "        cam = np.ones(target.shape[1:], dtype=np.float32)\n",
    "        # Multiply each weight with its conv output and then, sum\n",
    "        for i in range(len(target)):\n",
    "            # Unsqueeze to 4D\n",
    "            saliency_map = torch.unsqueeze(torch.unsqueeze(target[i, :, :],0),0)\n",
    "            #print(saliency_map)\n",
    "            #print(saliency_map.shape)\n",
    "            # Upsampling to input size\n",
    "            saliency_map = F.interpolate(saliency_map, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            if saliency_map.max() == saliency_map.min():\n",
    "                continue\n",
    "            # Scale between 0-1\n",
    "            norm_saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
    "            # Get the target score\n",
    "            w = F.softmax(self.extractor.forward_pass(input_image*norm_saliency_map)[1],dim=1)[0][target_class]\n",
    "            cam += w.data.cpu().numpy() * target[i, :, :].data.cpu().numpy()\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))  # Normalize between 0-1\n",
    "        cam = np.uint8(cam * 255)  # Scale between 0-255 to visualize\n",
    "        cam = np.uint8(Image.fromarray(cam).resize((input_image.shape[2],\n",
    "                       input_image.shape[3])))/255\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize((224,224)),\n",
    "    #transforms.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_example = 1\n",
    "model1 = torchvision.models.resnet50(pretrained=True)\n",
    "model1.fc = torch.nn.Linear(2048, 2)\n",
    "model1.load_state_dict(torch.load('NEW_test_resnet_final.pth'))\n",
    "model2 = torchvision.models.resnet50(pretrained=True)\n",
    "model2.fc = torch.nn.Linear(2048, 2)\n",
    "model2.load_state_dict(torch.load('New_resnet_test_surrogate_epoch0.pth'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(2048, 2)\n",
    "model.load_state_dict(torch.load('../../models/08-13/GRAAL.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateLoss(torch.nn.Module):\n",
    "    def __init__(self, beta, p):\n",
    "        super(SurrogateLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, outputs, labels):\n",
    "        f = torch.nn.functional.softmax(outputs, dim=-1)[:,1]\n",
    "        loss = -(labels*torch.log(f)) + (1-labels)*torch.log(self.beta**2 * self.p/(1-self.p) +f)\n",
    "        weights = torch.where(labels == 1, 1/self.p, 1/(1-self.p))\n",
    "        return (loss*weights).mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path = '/home/msouda/Datasets/true_anonymized/fr2_20130815T211708/fr2_20130815T211708_s0969_f0.jpg'\n",
    "img = Image.open(frame_path)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "img = transform(img)\n",
    "output = model(img.unsqueeze(0))\n",
    "SurrogateLoss(1,0.11)(output, torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.nn.functional.softmax(output, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(0.1235 +1.0373e-08)*(1/0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 =torchvision.models.resnet50(pretrained=True)\n",
    "features1.fc = torch.nn.Linear(2048, 2)\n",
    "features1.load_state_dict(torch.load('NEW_test_resnet_final.pth'))\n",
    "\n",
    "features2 = torchvision.models.resnet50(pretrained=True)\n",
    "features2.fc = torch.nn.Linear(2048, 2)\n",
    "features2.load_state_dict(torch.load('New_resnet_test_surrogate_epoch0.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.nn.Sequential(OrderedDict([\n",
    "    ('features', torch.nn.Sequential(OrderedDict([\n",
    "        ('0', torch.nn.Sequential(features1.conv1, features1.bn1, features1.relu, features1.maxpool)),\n",
    "        ('1', features1.layer1),\n",
    "        ('2', features1.layer2),\n",
    "        ('3', features1.layer3),\n",
    "        ('4', features1.layer4),\n",
    "        ('5', features1.avgpool)\n",
    "    ]))),\n",
    "    ('classifier',features1.fc)\n",
    "])\n",
    ")\n",
    "\n",
    "model2 = torch.nn.Sequential(OrderedDict([\n",
    "    ('features', torch.nn.Sequential(OrderedDict([\n",
    "        ('0', torch.nn.Sequential(features2.conv1, features2.bn1, features2.relu, features2.maxpool)),\n",
    "        ('1', features2.layer1),\n",
    "        ('2', features2.layer2),\n",
    "        ('3', features2.layer3),\n",
    "        ('4', features2.layer4),\n",
    "        ('5', features2.avgpool)\n",
    "    ]))),\n",
    "    ('classifier',features2.fc)\n",
    "])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_list = json.load(open('/home/msouda/Workspace/random_list.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vid = np.random.choice(random_list['test'])\n",
    "vid = 'true_anonymized/fr2_20140621T202024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = '235'\n",
    "frame_path = os.path.join(vid, vid.split('/')[1]+'_s'+frame_id+'_f0.jpg')\n",
    "frame_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path = 'true_anonymized/fr2_20130815T211708/fr2_20130815T211708_s0969_f0.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.nn.Sequential(OrderedDict([\n",
    "    ('features', torch.nn.Sequential(OrderedDict([\n",
    "        ('0', torch.nn.Sequential(model.conv1, model.bn1, model.relu, model.maxpool)),\n",
    "        ('1', model.layer1),\n",
    "        ('2', model.layer2),\n",
    "        ('3', model.layer3),\n",
    "        ('4', model.layer4),\n",
    "        ('5', model.avgpool)\n",
    "    ]))),\n",
    "    ('classifier',model.fc)\n",
    "])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = pd.read_csv('/home/msouda/Datasets/true_anonymized/annotations.csv', header=None, names = ['img_path', 'label']).assign(\n",
    "    video = lambda x: x.img_path.apply(lambda x: 'true_anonymized/'+x.split('/')[0]),\n",
    "    img_path = lambda x: x.img_path.apply(lambda x:'/home/msouda/Datasets/true_anonymized/'+ x))\n",
    "with open('training_GRAAL.json', 'r') as f:\n",
    "    train_metadata = json.load(f)\n",
    "\n",
    "test_list = train_metadata['test_video_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_list = annotations.query('video in @test_list').sample(10)\n",
    "select_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1.to(device)\n",
    "for img_path in select_list['img_path'].to_list():\n",
    "    fig, ax = plt.subplots(1,6, figsize=(30,8))\n",
    "    for i in range(5):\n",
    "        img = Image.open(img_path)\n",
    "        prep_img = transform(img).unsqueeze(0).to(device)\n",
    "        cam = ScoreCam(model1, i)\n",
    "        cam_img = cam.generate_cam(prep_img, 1)\n",
    "        ax[i].imshow(prep_img.squeeze().permute(1,2,0).cpu().numpy())\n",
    "        ax[i].imshow(cam_img, cmap='jet', alpha=0.5)\n",
    "        ax[i].axis('off')\n",
    "        ax[i].set_title(f'Layer {i}')\n",
    "    ax[5].imshow(prep_img.squeeze().permute(1,2,0).cpu().numpy())\n",
    "    ax[5].axis('off')\n",
    "    ax[5].set_title('Original')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1.to(device)\n",
    "for img_path in select_list['img_path'].to_list():\n",
    "    img = Image.open(img_path)\n",
    "    prep_img = transform(img).unsqueeze(0).to(device)\n",
    "    print(model(prep_img))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_list = annotations.query('label == 0').sample(5).img_path.tolist()\n",
    "for img_path in select_list:\n",
    "    fig, ax = plt.subplots(1,6, figsize=(30,8))\n",
    "    for i in range(5):\n",
    "        img = Image.open(img_path)\n",
    "        prep_img = transform(img).unsqueeze(0).to(device)\n",
    "        cam = ScoreCam(model, i)\n",
    "        cam_img = cam.generate_cam(prep_img, 1)\n",
    "        ax[i].imshow(prep_img.squeeze().permute(1,2,0).cpu().numpy())\n",
    "        ax[i].imshow(cam_img, cmap='jet', alpha=0.5)\n",
    "        ax[i].axis('off')\n",
    "        ax[i].set_title(f'Layer {i}')\n",
    "    ax[5].imshow(prep_img.squeeze().permute(1,2,0).cpu().numpy())\n",
    "    ax[5].axis('off')\n",
    "    ax[5].set_title('Original')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(select_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score cam\n",
    "with torch.no_grad():\n",
    "    for i in range(5):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        prep_img = transform(img).unsqueeze(0).to(device)\n",
    "        cams = []\n",
    "        for model in [model1, model2]:\n",
    "            model.to(device)\n",
    "            score_cam = ScoreCam(model, target_layer=i)\n",
    "            # Generate cam mask\n",
    "            cam = score_cam.generate_cam(prep_img, 1)\n",
    "            cams.append(cam)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax[0].imshow(prep_img.squeeze(0).permute(1, 2, 0).cpu())\n",
    "        ax[0].set_title('Original')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(prep_img.squeeze(0).permute(1, 2, 0).cpu())\n",
    "        ax[1].imshow(cams[0], cmap='jet', alpha=0.5)\n",
    "        ax[1].set_title('Model 1')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(prep_img.squeeze(0).permute(1, 2, 0).cpu())\n",
    "        ax[2].imshow(cams[1], cmap='jet', alpha=0.5)\n",
    "        ax[2].set_title('Model 2')\n",
    "        ax[2].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
